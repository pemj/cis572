\section{Results}
\label{sec:-res}
In order to approximate maximum accuracy values for our models, we 
carried out a series of tuning operations by way of an iterative binary 
search.  One hyperparameter at a time, we preceded to run the 
classifier with converging values until we had reached a sufficiently 
small difference in accuracy.  We recorded these values and explored 
the impact that small changes in multiple hyperparameters had on the 
accuracy of the model.  


The first classifier we attempted was Random Forest, primarily out of an 
appreciation for the pun value of using a forest to classify forests. 
Initially, our accuracy hovered between 60\% and 70\% on our validation 
data.  When we tuned the hyperparameters (increasing the number of 
features considered when splitting a tree, adding more trees to the 
forest, etc) of the Random Forest model, we reached 80\% accuracy on 
our validation set.  Unfortunately, our accuracy on the Kaggle 
competition remained below 70\%.  

We undertook similar experiments with the Gradient Boosting classifier 
(optimal results with an increased learning rate of approximately one 
third, increased max depth of five, increasing the number of boosting 
stages to 400, examining all features for a split), with somewhat 
better results (peak accuracy of 85\% on the validation set).  

We found that a k-value of 5 and a Euclidean distance measure
produced the highest-quality classifier from the k-Nearest Neighbor, 
model.  With those values, we reached a validation accuracy of about 
82\%.

Using an rbf kernel and a surprisingly high penalty parameter, with 
arbitrarily many iterations, our SVM reached approximately 81\% 
accuracy.

We attempted a Naive Bayes model, but were unable to reach an accuracy 
greater than 50\%.  We suspect that this low accuracy is a result of 
the interconnectedness of our feature vector.  As Naive Bayes relies on 
an assumption of independence between variables within the feature 
vector, and nature is somewhat infamously non-independent\cite{silent}, 
we remain largely unsurprised by this result.

It is perhaps unsurprising that, across all of the similarly accurate 
models, the same features kept appearing as the highest weights in the 
weight vectors of our various predictors.  Our neofeatures (difference 
between elevation and hydrology distances) were right up at the top, 
near Elevation, Roadway proximity, Hillshade, Fire Point proximity, and 
both Aspect values.

Combined, the ensemble of these models reached 85\% accuracy on our 
validation set, but still sat near 75\% on the Kaggle leaderboard.  
When we add in our second-level Random Forest classifier for cover 
types 1 and 2, our validation accuracy jumps to 91\%, and our Kaggle 
score clocks in at approximately 80\%.



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
