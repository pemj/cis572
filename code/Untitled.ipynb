{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test_ids = test['Id']\n",
    "\n",
    "def r(x):\n",
    "    if x+180>360:\n",
    "        return x-180\n",
    "    else:\n",
    "        return x+180\n",
    "\n",
    "## Add new columns for training data\n",
    "df['EVDtH'] = df.Elevation-df.Vertical_Distance_To_Hydrology\n",
    "df['EHDtH'] = df.Elevation-df.Horizontal_Distance_To_Hydrology*0.2\n",
    "df['Highwater'] = df.Vertical_Distance_To_Hydrology < 0\n",
    "df['Aspect2'] = df.Aspect.map(r)\n",
    "df.ix[df.Hillshade_3pm==0, 'Hillshade_3pm'] = df.Hillshade_3pm.median()\n",
    "\n",
    "## Add new columns for test data\n",
    "test['EVDtH'] = test.Elevation-test.Vertical_Distance_To_Hydrology\n",
    "test['EHDtH'] = test.Elevation-test.Horizontal_Distance_To_Hydrology*0.2\n",
    "test['Highwater'] = test.Vertical_Distance_To_Hydrology < 0\n",
    "test['Aspect2'] = test.Aspect.map(r)\n",
    "test.ix[test.Hillshade_3pm==0, 'Hillshade_3pm'] = test.Hillshade_3pm.median()\n",
    "\n",
    "features = [col for col in df.columns if col not in ['Cover_Type','Id','is_train']]\n",
    "\n",
    "X_train = df[features]\n",
    "X_test = test[features]\n",
    "y_training = df['Cover_Type']\n",
    "\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.36, loss='deviance',\n",
       "              max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2, n_estimators=400,\n",
       "              random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make GBM\n",
    "rt = .36\n",
    "md = 5\n",
    "ne = 400\n",
    "mf = None\n",
    "gbm = GradientBoostingClassifier(learning_rate=rt, max_depth=md, n_estimators=ne, max_features=mf)\n",
    "gbm.fit(X_train, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4b015bf111cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mscaled_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mscaled_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mscaled_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python34\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error)\u001b[0m\n\u001b[0;32m   2212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2213\u001b[0m         mgr = self._data.astype(\n\u001b[1;32m-> 2214\u001b[1;33m             dtype=dtype, copy=copy, raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m   2215\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python34\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   2500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2502\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2504\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python34\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, **kwargs)\u001b[0m\n\u001b[0;32m   2455\u001b[0m                                                  copy=align_copy)\n\u001b[0;32m   2456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2457\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python34\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, values)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[1;32m--> 371\u001b[1;33m                             values=values)\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python34\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, raise_on_error, values, klass)\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             newb = make_block(values,\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python34\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m   2627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2629\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2630\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Make Nearest Neighbor\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_training)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(X_train.astype(np.float))\n",
    "scaled_test = scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "scaled_train = pd.DataFrame(scaled_train, columns=features)\n",
    "scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "\n",
    "feature_importances = []\n",
    "for i in range(0, len(clf.feature_importances_)):\n",
    "    feature_importances.append((clf.feature_importances_[i] + 0.005)*5)\n",
    "\n",
    "col_index = 0\n",
    "for col in features:\n",
    "    scaled_train[col] = scaled_train[col]*feature_importances[col_index]\n",
    "    scaled_test[col] = scaled_test[col]*feature_importances[col_index]\n",
    "    col_index += 1\n",
    "\n",
    "neighbor = KNeighborsClassifier(n_neighbors=5) #weights=\"distance\"\n",
    "neighbor_fitted = neighbor.fit(scaled_train, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make SVM\n",
    "scaler = StandardScaler()\n",
    "scaled_train2 = scaler.fit_transform(X_train.astype(np.float))\n",
    "scaled_test2 = scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "scaled_train2 = pd.DataFrame(scaled_train2, columns=features)\n",
    "scaled_test2 = pd.DataFrame(scaled_test2, columns=features)\n",
    "\n",
    "rbf_svc = svm.SVC(C=1500, kernel=\"rbf\", max_iter=-1) #5.5, 200\n",
    "svm_fitted = rbf_svc.fit(scaled_train2, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Combine predictions\n",
    "gbm_predict = gbm.predict(X_test)\n",
    "nn_predict = neighbor_fitted.predict(scaled_test)\n",
    "svm_predict = svm_fitted.predict(scaled_test2)\n",
    "\n",
    "voted_predict = []\n",
    "for i in range(0,len(svm_predict)):\n",
    "    a = np.array([gbm_predict[i], svm_predict[i], nn_predict[i]])\n",
    "    (values,counts) = np.unique(a,return_counts=True)\n",
    "    ind=np.argmax(counts)\n",
    "    voted_predict.append(values[ind])\n",
    "\n",
    "with open('output.csv', \"w\") as outfile:\n",
    "    outfile.write(\"Id,Cover_Type\\n\")\n",
    "    for e, val in enumerate(voted_predict):\n",
    "        outfile.write(str(test_ids[e])+\",\"+str(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
